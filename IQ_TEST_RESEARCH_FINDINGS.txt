================================================================================
COMPREHENSIVE RESEARCH: IQ TEST DEVELOPMENT, METHODOLOGY, AND STANDARDS
================================================================================

Date: 2025-11-15
Author: Research compiled via web search and academic sources
Purpose: Understanding the established processes, categories, and methodologies
         for IQ test development and question generation

================================================================================
EXECUTIVE SUMMARY
================================================================================

This research addresses four key questions about IQ testing:

1. IS THE PROCESS FOR GENERATING IQ QUESTIONS KNOWN?
   YES - The process is well-documented and follows established psychometric
   methodologies including theoretical frameworks, pilot testing, statistical
   analysis (IRT/CTT), and standardization.

2. ARE THE CATEGORIES OF IQ QUESTIONS KNOWN?
   YES - Question categories are well-established across major tests, measuring
   specific cognitive domains: verbal comprehension, perceptual/spatial
   reasoning, working memory, processing speed, mathematical reasoning, and
   logical reasoning.

3. IS THE SCORING FORMULA KNOWN?
   YES - Modern IQ tests use the "deviation IQ" method with a well-defined
   formula: IQ = 100 + (15 × z), where z is the standardized score.
   Raw scores are transformed to a normal distribution (mean=100, SD=15).

4. WHAT DO WE KNOW ABOUT THE IQ PROCESS?
   The IQ testing process is highly standardized and scientifically rigorous,
   involving test construction, norming on large representative samples
   (2,000+ participants), psychometric validation, and continuous refinement.

================================================================================
PART 1: IQ TEST QUESTION CATEGORIES AND TYPES
================================================================================

1.1 PRIMARY COGNITIVE DOMAINS
------------------------------

IQ tests measure intelligence across well-established cognitive domains:

A. VERBAL COMPREHENSION
   - Reading and language comprehension
   - Vocabulary and word meanings
   - Verbal reasoning and analogies
   - Abstract verbal reasoning

B. PERCEPTUAL REASONING / SPATIAL REASONING
   - Mental manipulation of 3D objects
   - Spatial visualization
   - Visual pattern recognition
   - Abstract spatial problem-solving

C. WORKING MEMORY
   - Short-term information retention
   - Mental manipulation of information
   - Sequence recall
   - Auditory and visual memory

D. PROCESSING SPEED
   - Speed of information processing
   - Visual scanning and discrimination
   - Rapid decision-making
   - Psychomotor speed

E. MATHEMATICAL REASONING
   - Quantitative reasoning
   - Numerical problem-solving
   - Mathematical logic (not just calculation)
   - Number theory and relationships

F. LOGICAL REASONING
   - Deductive reasoning (syllogisms)
   - Inductive reasoning (pattern inference)
   - Set theory and classification
   - If-then conditional logic

1.2 FLUID VS. CRYSTALLIZED INTELLIGENCE
----------------------------------------

Intelligence is conceptually divided into two broad categories:

FLUID INTELLIGENCE (Gf)
- Ability to think logically and solve novel problems
- Independent of acquired knowledge
- Abstract reasoning and pattern recognition
- Peaks in early adulthood and gradually declines

CRYSTALLIZED INTELLIGENCE (Gc)
- Acquired knowledge and skills
- Dependent on education and experience
- Vocabulary, facts, and procedures
- Tends to remain stable or increase with age

1.3 QUESTION TYPES IN MAJOR IQ TESTS
-------------------------------------

WECHSLER ADULT INTELLIGENCE SCALE (WAIS-IV)

Verbal Subtests:
- Information: General knowledge questions
- Comprehension: Understanding of social rules and concepts
- Arithmetic: Mathematical word problems
- Digit Span: Repeat numbers forward/backward
- Similarities: Identify commonalities between concepts
- Vocabulary: Define words

Performance/Perceptual Subtests:
- Matrix Reasoning: Complete visual pattern matrices
- Block Design: Replicate patterns with blocks
- Picture Completion: Identify missing elements
- Picture Arrangement: Sequence images logically
- Object Assembly: Construct objects from pieces
- Digit Symbol: Copy symbols paired with numbers
- Symbol Search: Scan for target symbols

STANFORD-BINET INTELLIGENCE SCALES (5th Edition)

Five Factor Structure:
- Fluid Reasoning: Abstract problem-solving
- Knowledge: Acquired information and vocabulary
- Quantitative Reasoning: Mathematical problem-solving
- Visual-Spatial Processing: Mental rotation and spatial tasks
- Working Memory: Short-term retention and manipulation

RAVEN'S PROGRESSIVE MATRICES

Structure:
- 60 multiple-choice questions in 5 sets (A-E)
- Each set contains 12 items of increasing difficulty
- Pure pattern recognition and abstract reasoning
- Non-verbal, culturally neutral design

Pattern Types:
- Progression: Elements change systematically
- Rotation: Shapes rotate in predictable ways
- Addition/Subtraction: Elements are added or removed
- Transformation: Shapes transform according to rules
- Matrix completion: Identify missing piece in 3x3 or 2x2 grid

================================================================================
PART 2: THE IQ QUESTION DEVELOPMENT PROCESS
================================================================================

2.1 THEORETICAL FOUNDATION
--------------------------

Step 1: Choose Theoretical Framework
- Spearman's g-factor (general intelligence)
- Cattell-Horn-Carroll (CHC) theory (hierarchical model)
- Gardner's multiple intelligences
- Sternberg's triarchic theory

The chosen theory guides which cognitive abilities to measure and how to
structure the test.

2.2 TEST CONSTRUCTION PROCESS
------------------------------

Step 2: Define the Construct
- Clearly specify what aspect of intelligence is being measured
- Identify target cognitive domains
- Determine test purpose (clinical, educational, research)

Step 3: Literature Review
- Review existing tests and research
- Examine psychometric properties of similar assessments
- Identify gaps in current testing approaches

Step 4: Item Generation
- Create diverse range of questions covering different cognitive aspects
- Ensure items vary in difficulty to discriminate across ability levels
- Design questions with clear, unambiguous correct answers
- Include plausible distractors in multiple-choice items
- Aim for cultural neutrality and accessibility

2.3 PILOT TESTING AND VALIDATION
---------------------------------

Step 5: Pilot Testing
- Administer test to small representative sample
- Gather feedback on clarity, difficulty, and relevance
- Identify problematic or ambiguous items
- Collect timing data for test administration

Step 6: Statistical Analysis
Two primary approaches exist:

CLASSICAL TEST THEORY (CTT)
- Analyze item difficulty (percentage answering correctly)
- Calculate discrimination index (correlation with total score)
- Assess internal consistency (Cronbach's alpha)
- Evaluate test-retest reliability

ITEM RESPONSE THEORY (IRT)
Modern standard for test development, providing:

a) Item Parameters:
   - Difficulty (b): Ability level for 50% correct probability
   - Discrimination (a): How well item differentiates ability levels
   - Guessing (c): Probability of random correct response

b) Advantages over CTT:
   - Person parameter invariance (scores independent of specific items)
   - Item banking capabilities
   - Adaptive testing possibilities
   - Variable measurement error across ability levels
   - Test information functions showing precision

c) IRT Models:
   - 1-Parameter (Rasch): Uses only difficulty
   - 2-Parameter: Uses difficulty and discrimination
   - 3-Parameter: Adds guessing parameter

Step 7: Item Refinement
- Eliminate or revise items based on statistical performance
- Items with poor discrimination are removed
- Items too easy or too hard may be adjusted or eliminated
- Ambiguous items are clarified or removed

2.4 STANDARDIZATION AND NORMING
--------------------------------

Step 8: Norming Sample Collection

Sample Requirements:
- Large sample size (typically 2,000+ participants)
- Representative of target population demographics:
  * Age distribution
  * Gender balance
  * Ethnic diversity
  * Geographic representation
  * Educational background
  * Socioeconomic status

Example: WAIS-IV standardized on 2,200 people aged 16-90

Step 9: Norm Development
- Administer final test version to norming sample
- Collect raw scores across entire sample
- Transform raw scores to normalized distribution
- Establish percentile ranks and standard scores
- Create age-based norms (account for developmental changes)
- Develop continuous norming procedures for precise comparisons

Types of Norms:
- Percentile norms: Ranking relative to norming sample
- Age norms: Account for developmental differences
- Grade norms: For educational contexts
- National vs. local norms: Population-specific standards

2.5 VALIDATION PROCESS
----------------------

Step 10: Reliability Testing

Test-Retest Reliability:
- Same individuals take test multiple times
- Correlation between administrations calculated
- Standards: ICC >0.4, Pearson r >0.3, Cohen's kappa >0.4

Internal Consistency:
- Measure of inter-item correlations
- Cronbach's alpha ≥0.6 considered adequate
- Top-tier tests achieve α = 0.93-0.95

Standard Error of Measurement:
- Best modern tests: ~3 points
- Confidence intervals: typically ±10 points

Step 11: Validity Evidence

Construct Validity:
- Does test measure intended cognitive abilities?
- Factor analysis to confirm theoretical structure
- Convergent validity with related constructs
- Discriminant validity from unrelated constructs

Criterion Validity:
- Predictive validity: Future outcomes (school grades r=.55)
- Concurrent validity: Correlations with established tests (r=.76-.86)
- IQ predicts: academic achievement, job performance, health outcomes

Content Validity:
- Items adequately represent cognitive domain
- Expert review of item relevance and coverage
- Alignment with theoretical framework

2.6 ONGOING REFINEMENT
----------------------

- Periodic renorming (every 10-15 years typically)
- Continuous item analysis and improvement
- Updates to reflect current research
- Addressing cultural and linguistic considerations
- Recalibration to prevent Flynn Effect bias (scores increasing over time)

================================================================================
PART 3: IQ SCORING FORMULAS AND NORMALIZATION
================================================================================

3.1 THE DEVIATION IQ METHOD
----------------------------

Modern IQ tests use the "deviation IQ" method, replacing older ratio-based
approaches (Mental Age / Chronological Age × 100).

STANDARD SCORING FORMULA:

IQ = 100 + (15 × z)

Where:
- 100 = Mean IQ score
- 15 = Standard deviation (most tests)
- z = z-score (standardized score)

Z-SCORE CALCULATION:

z = (X - μ) / σ

Where:
- X = Individual's raw score
- μ (mu) = Mean raw score of norming sample
- σ (sigma) = Standard deviation of norming sample

3.2 STANDARD DEVIATION VARIATIONS
----------------------------------

Most tests use SD = 15 (Wechsler scales)
Stanford-Binet uses SD = 16

This affects score interpretation:
- WAIS: IQ 115 = one SD above mean (84th percentile)
- Stanford-Binet: IQ 116 = one SD above mean (84th percentile)

3.3 SCORE DISTRIBUTION
----------------------

IQ scores follow a normal (Gaussian) distribution:

EMPIRICAL RULE (68-95-99.7 Rule):

68% of population: IQ 85-115 (within ±1 SD)
95% of population: IQ 70-130 (within ±2 SD)
99.7% of population: IQ 55-145 (within ±3 SD)

SPECIFIC PERCENTILES:

IQ Score | Percentile | % of Population
---------|------------|----------------
145      | 99.9%      | 0.1% (1 in 1000)
130      | 98%        | 2% (gifted threshold)
115      | 84%        | 16% above this point
100      | 50%        | Population median
85       | 16%        | 16% below this point
70       | 2%         | 2% (intellectual disability threshold)
55       | 0.1%       | 0.1% (1 in 1000)

3.4 RAW SCORE TRANSFORMATION PROCESS
-------------------------------------

Step 1: Administer test, collect raw score (e.g., 42 correct out of 60)

Step 2: Look up norming table for demographic group
- Age-specific norms most common
- Some tests use education-adjusted norms

Step 3: Convert raw score to scaled score
- Each subtest typically scaled to mean=10, SD=3

Step 4: Sum scaled scores across subtests

Step 5: Convert to composite IQ score
- Use norming tables
- Apply deviation IQ formula
- Mean = 100, SD = 15 (or 16 for Stanford-Binet)

Step 6: Calculate confidence interval
- Typically 95% confidence interval (±1.96 SEM)
- Example: IQ 115 with SEM=3 → 95% CI = [109, 121]

3.5 SCORE INTERPRETATION RANGES
--------------------------------

WECHSLER CLASSIFICATION SYSTEM:

130+     : Very Superior
120-129  : Superior
110-119  : High Average
90-109   : Average
80-89    : Low Average
70-79    : Borderline
Below 70 : Extremely Low

Note: Different organizations use slightly different classifications, but
the statistical meaning (percentile ranks) remains consistent.

================================================================================
PART 4: PSYCHOMETRIC STANDARDS AND BEST PRACTICES
================================================================================

4.1 RELIABILITY STANDARDS
--------------------------

INTERNAL CONSISTENCY:
- Minimum acceptable: Cronbach's α ≥ 0.60
- Good: α ≥ 0.70
- Excellent: α ≥ 0.90
- Top IQ tests achieve: α = 0.93-0.95

TEST-RETEST RELIABILITY:
- Minimum acceptable: ICC > 0.4 or Pearson r > 0.3
- Good: r > 0.7
- Excellent: r > 0.9
- Time interval matters (longer gaps = lower correlations)

INTER-RATER RELIABILITY:
- Essential for subjectively scored items
- Kappa > 0.4 acceptable
- Most modern IQ tests use objective scoring to eliminate this issue

4.2 VALIDITY STANDARDS
----------------------

CONTENT VALIDITY:
- Expert panel review
- Alignment with theoretical framework
- Comprehensive domain coverage
- No systematic construct-irrelevant variance

CRITERION VALIDITY:
- Concurrent: r > 0.70 with established IQ tests
- Predictive: r = 0.50-0.60 for academic achievement
- High-quality tests show correlations of r = 0.76-0.86 with gold-standard
  cognitive tests

CONSTRUCT VALIDITY:
- Factor analysis confirms theoretical structure
- Convergent validity with related constructs
- Discriminant validity from unrelated constructs
- Note: Some researchers question IQ tests' construct validity despite
  strong predictive validity

4.3 FAIRNESS AND CULTURAL CONSIDERATIONS
-----------------------------------------

CULTURAL FAIRNESS:
- Minimize language-specific content for non-verbal tests
- Avoid culture-specific knowledge requirements
- Pilot test across diverse populations
- Differential Item Functioning (DIF) analysis to detect bias

Raven's Progressive Matrices exemplifies cultural fairness:
- Purely non-verbal
- No language requirements
- Minimal cultural knowledge needed
- Administrable globally

ACCOMMODATION CONSIDERATIONS:
- Time extensions for processing speed differences
- Alternative formats for sensory impairments
- Language translations with validation
- Appropriate norms for special populations

4.4 ETHICAL GUIDELINES
----------------------

- Informed consent required
- Qualified administrator required (training/certification)
- Results interpreted in context (not sole decision factor)
- Confidentiality maintained
- Misuse prevention (high-stakes decisions should use multiple measures)
- Regular updates and renorming to prevent obsolescence

4.5 TEST SECURITY
-----------------

- Items kept confidential to prevent practice effects
- Limited public exposure of actual test content
- Secure administration environments
- Prevention of coaching that inflates scores artificially

================================================================================
PART 5: WHAT WE KNOW ABOUT THE IQ PROCESS - SYNTHESIS
================================================================================

5.1 WELL-ESTABLISHED KNOWLEDGE
-------------------------------

YES, WE KNOW:

1. Question Categories and Types
   - Six primary cognitive domains are well-defined
   - Specific question formats have decades of research
   - Major tests (WAIS, Stanford-Binet, Raven's) are thoroughly documented

2. Development Process
   - Multi-stage process: theory → design → pilot → analysis → norming
   - Statistical methods (IRT/CTT) are standardized
   - Validation procedures are rigorous and documented

3. Scoring Formula
   - Deviation IQ method is universal standard
   - Formula: IQ = 100 + (15 × z-score)
   - Normal distribution with mean=100, SD=15 (or 16)

4. Psychometric Standards
   - Reliability coefficients have established thresholds
   - Validity evidence requirements are well-defined
   - Professional standards published by APA and other organizations

5. Norming Procedures
   - Large representative samples required (2,000+)
   - Demographic matching to population
   - Transformation to normal distribution
   - Periodic renorming necessary (every 10-15 years)

5.2 AREAS OF ONGOING RESEARCH AND DEBATE
-----------------------------------------

WHAT REMAINS UNCERTAIN OR DEBATED:

1. Construct Validity
   - Whether IQ tests truly measure "intelligence" as a unified construct
   - Relationship between test performance and real-world intelligence
   - Alternative theories of intelligence (multiple intelligences, etc.)

2. Cultural Fairness
   - Extent of cultural bias in "culture-fair" tests
   - Appropriate use across diverse populations
   - SES effects on test performance

3. Predictive Limitations
   - IQ explains ~25-30% of variance in academic achievement (r²=.55²≈.30)
   - Many other factors influence real-world success
   - Debate over what IQ tests actually predict

4. Flynn Effect
   - IQ scores have risen ~3 points per decade globally
   - Causes remain debated (education, nutrition, test sophistication)
   - Implications for test interpretation and norming

5. Specific Question Generation Rules
   - While categories are known, specific algorithms for generating
     high-quality items are often proprietary
   - Test publishers guard specific item creation methodologies
   - No universal "IQ question generator" exists

5.3 PROPRIETARY VS. PUBLIC KNOWLEDGE
-------------------------------------

PUBLIC/KNOWN:
- Theoretical frameworks
- General question types and formats
- Statistical analysis methods (IRT/CTT)
- Scoring formulas and normalization
- Psychometric standards
- General development process

PROPRIETARY/PROTECTED:
- Specific test items (copyrighted)
- Exact item generation algorithms
- Full norming data tables
- Item bank databases
- Detailed scoring keys
- Internal validity studies

This is why professional IQ tests (WAIS, Stanford-Binet) are:
- Expensive to administer
- Require certified administrators
- Not freely available online
- Periodically updated with new item pools

5.4 IMPLICATIONS FOR AI-GENERATED IQ QUESTIONS
-----------------------------------------------

WHAT WE CAN DO:
- Follow established question type taxonomies
- Implement known psychometric standards
- Use standard scoring formulas
- Conduct pilot testing and statistical validation
- Build diverse question pools across cognitive domains
- Apply IRT analysis to calibrate difficulty

CHALLENGES:
- Achieving construct validity without large-scale validation
- Ensuring cultural fairness across diverse populations
- Calibrating difficulty without large norming samples
- Avoiding unintentional reproduction of copyrighted items
- Matching quality of professionally developed tests

OPPORTUNITIES:
- Large-scale question generation through AI
- Rapid iteration and improvement
- Adaptive testing possibilities
- Cost reduction (more accessible testing)
- Innovation in question formats

================================================================================
PART 6: RECOMMENDATIONS FOR IQ TRACKER PROJECT
================================================================================

6.1 ALIGNMENT WITH ESTABLISHED STANDARDS
-----------------------------------------

CURRENT IMPLEMENTATION STRENGTHS:
✓ Question categories align with established cognitive domains
✓ Multi-LLM generation approach mirrors expert committee development
✓ Arbiter evaluation mimics psychometric review process
✓ Difficulty levels (easy/medium/hard) follow industry practice
✓ Deduplication prevents item repetition

AREAS FOR ENHANCEMENT:

1. Pilot Testing Phase
   - Implement small-scale user testing before full deployment
   - Collect performance data on questions
   - Calculate actual difficulty (% correct) vs. intended difficulty

2. Statistical Analysis
   - Implement IRT analysis on collected response data
   - Calculate item discrimination parameters
   - Identify and remove low-quality items
   - Recalibrate difficulty estimates

3. Scoring Refinement
   - Current simplified algorithm can be improved with data
   - Implement proper deviation IQ scoring once norming data exists
   - Build age-specific norms if user base grows

4. Validation Studies
   - Correlate scores with educational achievement
   - Compare with established IQ tests (if feasible)
   - Track test-retest reliability
   - Measure internal consistency

5. Quality Metrics
   - Establish minimum arbiter scores (currently 0.7 - good choice)
   - Add item discrimination to evaluation criteria
   - Track approval rates by question type
   - Monitor for cultural bias

6.2 REALISTIC EXPECTATIONS
---------------------------

MVP STAGE (Current):
- Focus on question quality and diversity
- Build large item bank
- Ensure technical infrastructure works
- Collect initial user data

GROWTH STAGE:
- Analyze performance data
- Implement IRT-based calibration
- Refine scoring algorithm
- Begin validation studies

MATURE STAGE:
- Establish test-retest reliability evidence
- Publish psychometric properties
- Seek external validation
- Consider professional review/certification

6.3 SCIENTIFIC VALIDITY CAVEAT
-------------------------------

Important Context:
- Professional IQ tests take years to develop and validate
- Large norming samples (2,000+) are expensive and time-consuming
- Full construct validity requires extensive research
- Early versions should be positioned as "cognitive assessment" rather
  than clinical IQ testing

Recommended Messaging:
- "Track your cognitive performance over time"
- "Practice IQ-style questions across multiple domains"
- "Identify cognitive strengths and areas for growth"
- Avoid claiming equivalence to clinical IQ tests

================================================================================
PART 7: KEY REFERENCES AND RESOURCES
================================================================================

FOUNDATIONAL TEXTS:
- Wechsler Adult Intelligence Scale (WAIS) technical manual
- Stanford-Binet Intelligence Scales documentation
- Raven's Progressive Matrices research papers
- APA Standards for Educational and Psychological Testing

STATISTICAL METHODS:
- Item Response Theory (IRT) literature
- Classical Test Theory (CTT) foundations
- Psychometric validation frameworks
- Factor analysis for intelligence research

THEORETICAL FRAMEWORKS:
- Spearman's g-factor theory
- Cattell-Horn-Carroll (CHC) theory
- Fluid vs. crystallized intelligence (Gf-Gc theory)
- Multiple intelligences (Gardner)

ORGANIZATIONS:
- American Psychological Association (APA)
- National Council on Measurement in Education (NCME)
- Society for Industrial and Organizational Psychology (SIOP)
- International Test Commission (ITC)

================================================================================
CONCLUSIONS
================================================================================

TO YOUR ORIGINAL QUESTIONS:

1. IS THE PROCESS FOR GENERATING IQ QUESTIONS KNOWN?

   YES - Comprehensively documented through:
   - Theoretical framework selection
   - Item generation based on cognitive domains
   - Pilot testing and statistical analysis (IRT/CTT)
   - Psychometric validation
   - Ongoing refinement

   However, specific proprietary methods used by test publishers for creating
   individual items may not be fully public.

2. ARE THE CATEGORIES OF IQ QUESTIONS KNOWN?

   YES - Well-established categories include:
   - Verbal Comprehension
   - Perceptual/Spatial Reasoning
   - Working Memory
   - Processing Speed
   - Mathematical Reasoning
   - Logical Reasoning

   These map to fluid intelligence (Gf) and crystallized intelligence (Gc)
   with extensive research supporting their validity.

3. IS THE SCORING FORMULA KNOWN?

   YES - The deviation IQ method is universal:

   IQ = 100 + (15 × z-score)

   Where z = (raw score - mean) / standard deviation

   This produces a normal distribution with mean=100 and SD=15.
   The process of transforming raw scores to IQ scores is standardized
   and transparent.

4. WHAT DO WE KNOW ABOUT THE IQ PROCESS?

   We have extensive scientific knowledge about:
   - Test construction methodology
   - Statistical validation procedures
   - Norming and standardization requirements
   - Reliability and validity standards
   - Question types and cognitive domains
   - Scoring and interpretation

   What remains proprietary or debated:
   - Specific item generation algorithms
   - Exact copyrighted test items
   - Full construct validity of IQ as a concept
   - Cultural fairness challenges
   - Optimal theoretical frameworks

BOTTOM LINE:

The science of IQ testing is well-established and transparent in its methods,
standards, and formulas. While specific test items are proprietary, the
overall process, psychometric standards, and scoring methods are public
knowledge and extensively documented in academic literature.

Developing a valid IQ test requires:
1. Following established psychometric standards
2. Conducting large-scale norming studies
3. Rigorous statistical validation
4. Ongoing refinement based on performance data

The IQ Tracker project has a solid foundation by following established
question categories and implementing quality controls. With proper data
collection and statistical analysis, it can achieve meaningful cognitive
assessment, though full equivalence to clinical IQ tests requires extensive
validation research.

================================================================================
END OF RESEARCH DOCUMENT
================================================================================
